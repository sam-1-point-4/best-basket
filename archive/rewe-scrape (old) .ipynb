{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zip 10623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setting PLZ and market on: https://shop.rewe.de/p/philadelphia-natur-doppelrahmstufe-175g/575043\n",
      "[WARN] Failed to enter PLZ.\n",
      "[WARN] No 'Abholmarkt wÃ¤hlen' button found.\n",
      "[ACTION] If a CAPTCHA appears, please solve it manually in the browser.\n",
      "[INFO] Scraping category: https://shop.rewe.de/p/philadelphia-natur-doppelrahmstufe-175g/575043 -> https://shop.rewe.de/p/philadelphia-natur-doppelrahmstufe-175g/575043\n",
      "[INFO] No cookie modal or already accepted.\n",
      "[INFO] No Abholservice modal or already handled.\n",
      "[ERROR] Error scraping products: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=137.0.7151.68)\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000104cb8708 cxxbridge1$str$ptr + 2729312\n",
      "1   chromedriver                        0x0000000104cb096c cxxbridge1$str$ptr + 2697156\n",
      "2   chromedriver                        0x0000000104802728 cxxbridge1$string$len + 90444\n",
      "3   chromedriver                        0x00000001047dc744 chromedriver + 132932\n",
      "4   chromedriver                        0x0000000104871c9c cxxbridge1$string$len + 546496\n",
      "5   chromedriver                        0x000000010488abe0 cxxbridge1$string$len + 648708\n",
      "6   chromedriver                        0x000000010483dbc0 cxxbridge1$string$len + 333284\n",
      "7   chromedriver                        0x0000000104c7c298 cxxbridge1$str$ptr + 2482416\n",
      "8   chromedriver                        0x0000000104c7f52c cxxbridge1$str$ptr + 2495364\n",
      "9   chromedriver                        0x0000000104c5dae0 cxxbridge1$str$ptr + 2357560\n",
      "10  chromedriver                        0x0000000104c7fdb4 cxxbridge1$str$ptr + 2497548\n",
      "11  chromedriver                        0x0000000104c4edec cxxbridge1$str$ptr + 2296900\n",
      "12  chromedriver                        0x0000000104c9fc4c cxxbridge1$str$ptr + 2628260\n",
      "13  chromedriver                        0x0000000104c9fdd8 cxxbridge1$str$ptr + 2628656\n",
      "14  chromedriver                        0x0000000104cb05b8 cxxbridge1$str$ptr + 2696208\n",
      "15  libsystem_pthread.dylib             0x00000001850fa034 _pthread_start + 136\n",
      "16  libsystem_pthread.dylib             0x00000001850f4e3c thread_start + 8\n",
      "\n",
      "[INFO] Total products found: 0\n",
      "[INFO] https://shop.rewe.de/p/philadelphia-natur-doppelrahmstufe-175g/575043: 0 products scraped.\n",
      "[INFO] Scraping category: https://shop.rewe.de/p/hellas-hirtenkaese-200g/8839277 -> https://shop.rewe.de/p/hellas-hirtenkaese-200g/8839277\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=137.0.7151.68)\nStacktrace:\n0   chromedriver                        0x0000000104cb8708 cxxbridge1$str$ptr + 2729312\n1   chromedriver                        0x0000000104cb096c cxxbridge1$str$ptr + 2697156\n2   chromedriver                        0x0000000104802728 cxxbridge1$string$len + 90444\n3   chromedriver                        0x00000001047dc744 chromedriver + 132932\n4   chromedriver                        0x0000000104871c9c cxxbridge1$string$len + 546496\n5   chromedriver                        0x000000010488abe0 cxxbridge1$string$len + 648708\n6   chromedriver                        0x000000010483dbc0 cxxbridge1$string$len + 333284\n7   chromedriver                        0x0000000104c7c298 cxxbridge1$str$ptr + 2482416\n8   chromedriver                        0x0000000104c7f52c cxxbridge1$str$ptr + 2495364\n9   chromedriver                        0x0000000104c5dae0 cxxbridge1$str$ptr + 2357560\n10  chromedriver                        0x0000000104c7fdb4 cxxbridge1$str$ptr + 2497548\n11  chromedriver                        0x0000000104c4edec cxxbridge1$str$ptr + 2296900\n12  chromedriver                        0x0000000104c9fc4c cxxbridge1$str$ptr + 2628260\n13  chromedriver                        0x0000000104c9fdd8 cxxbridge1$str$ptr + 2628656\n14  chromedriver                        0x0000000104cb05b8 cxxbridge1$str$ptr + 2696208\n15  libsystem_pthread.dylib             0x00000001850fa034 _pthread_start + 136\n16  libsystem_pthread.dylib             0x00000001850f4e3c thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNoSuchWindowException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 166\u001b[39m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[DONE] All products saved to rewe-products.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 154\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    152\u001b[39m category = extract_category(url)\n\u001b[32m    153\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[INFO] Scraping category: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m products = \u001b[43mscrape_products_from_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m result[category] = products\n\u001b[32m    156\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[INFO] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(products)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m products scraped.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36mscrape_products_from_category\u001b[39m\u001b[34m(driver, url)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mscrape_products_from_category\u001b[39m(driver, url):\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[43mdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     accept_cookies(driver)\n\u001b[32m     82\u001b[39m     select_abholservice(driver)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/best-basket/.venv/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:472\u001b[39m, in \u001b[36mWebDriver.get\u001b[39m\u001b[34m(self, url)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    455\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Navigate the browser to the specified URL in the current window or\u001b[39;00m\n\u001b[32m    456\u001b[39m \u001b[33;03m    tab.\u001b[39;00m\n\u001b[32m    457\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    470\u001b[39m \u001b[33;03m    >>> driver.get(\"https://example.com\")\u001b[39;00m\n\u001b[32m    471\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43murl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/best-basket/.venv/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:447\u001b[39m, in \u001b[36mWebDriver.execute\u001b[39m\u001b[34m(self, driver_command, params)\u001b[39m\n\u001b[32m    445\u001b[39m response = \u001b[38;5;28mself\u001b[39m.command_executor.execute(driver_command, params)\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    448\u001b[39m     response[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._unwrap_value(response.get(\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/best-basket/.venv/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py:232\u001b[39m, in \u001b[36mErrorHandler.check_response\u001b[39m\u001b[34m(self, response)\u001b[39m\n\u001b[32m    230\u001b[39m         alert_text = value[\u001b[33m\"\u001b[39m\u001b[33malert\u001b[39m\u001b[33m\"\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[31mNoSuchWindowException\u001b[39m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=137.0.7151.68)\nStacktrace:\n0   chromedriver                        0x0000000104cb8708 cxxbridge1$str$ptr + 2729312\n1   chromedriver                        0x0000000104cb096c cxxbridge1$str$ptr + 2697156\n2   chromedriver                        0x0000000104802728 cxxbridge1$string$len + 90444\n3   chromedriver                        0x00000001047dc744 chromedriver + 132932\n4   chromedriver                        0x0000000104871c9c cxxbridge1$string$len + 546496\n5   chromedriver                        0x000000010488abe0 cxxbridge1$string$len + 648708\n6   chromedriver                        0x000000010483dbc0 cxxbridge1$string$len + 333284\n7   chromedriver                        0x0000000104c7c298 cxxbridge1$str$ptr + 2482416\n8   chromedriver                        0x0000000104c7f52c cxxbridge1$str$ptr + 2495364\n9   chromedriver                        0x0000000104c5dae0 cxxbridge1$str$ptr + 2357560\n10  chromedriver                        0x0000000104c7fdb4 cxxbridge1$str$ptr + 2497548\n11  chromedriver                        0x0000000104c4edec cxxbridge1$str$ptr + 2296900\n12  chromedriver                        0x0000000104c9fc4c cxxbridge1$str$ptr + 2628260\n13  chromedriver                        0x0000000104c9fdd8 cxxbridge1$str$ptr + 2628656\n14  chromedriver                        0x0000000104cb05b8 cxxbridge1$str$ptr + 2696208\n15  libsystem_pthread.dylib             0x00000001850fa034 _pthread_start + 136\n16  libsystem_pthread.dylib             0x00000001850f4e3c thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "\n",
    "def extract_category(url: str) -> str:\n",
    "    match = re.search(r\"/c/([^/?]+)\", url)\n",
    "    return match.group(1) if match else url\n",
    "\n",
    "def read_links_from_file(file_path: str):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def accept_cookies(driver):\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        buttons = wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, \"button\")))\n",
    "        for btn in buttons:\n",
    "            if \"alle erlauben\" in btn.text.lower():\n",
    "                btn.click()\n",
    "                print(\"[INFO] Cookies accepted.\")\n",
    "                time.sleep(2)\n",
    "                return\n",
    "    except Exception:\n",
    "        print(\"[INFO] No cookie modal or already accepted.\")\n",
    "\n",
    "def select_abholservice(driver):\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        buttons = wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, \"button\")))\n",
    "        for btn in buttons:\n",
    "            if \"abholservice\" in btn.text.lower():\n",
    "                btn.click()\n",
    "                print(\"[INFO] Abholservice selected.\")\n",
    "                time.sleep(2)\n",
    "                return\n",
    "    except Exception:\n",
    "        print(\"[INFO] No Abholservice modal or already handled.\")\n",
    "\n",
    "def enter_plz_and_select_market(driver):\n",
    "    try:\n",
    "        time.sleep(2)\n",
    "        plz_input = driver.find_element(By.TAG_NAME, \"input\")\n",
    "        plz_input.clear()\n",
    "        plz_input.send_keys(\"10115\")\n",
    "        plz_input.submit()\n",
    "        print(\"[INFO] PLZ entered and submitted.\")\n",
    "        time.sleep(3)\n",
    "    except Exception:\n",
    "        print(\"[WARN] Failed to enter PLZ.\")\n",
    "\n",
    "    try:\n",
    "        for _ in range(20):\n",
    "            buttons = driver.find_elements(By.TAG_NAME, \"button\")\n",
    "            for btn in buttons:\n",
    "                if \"abholmarkt wÃ¤hlen\" in btn.text.lower():\n",
    "                    btn.click()\n",
    "                    print(\"[INFO] Abholmarkt selected.\")\n",
    "                    time.sleep(3)\n",
    "                    return\n",
    "            time.sleep(1)\n",
    "        print(\"[WARN] No 'Abholmarkt wÃ¤hlen' button found.\")\n",
    "    except Exception:\n",
    "        print(\"[ERROR] Error selecting Abholmarkt.\")\n",
    "\n",
    "def enable_stealth(driver):\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "        \"source\": \"\"\"\n",
    "        Object.defineProperty(navigator, 'webdriver', {get: () => undefined});\n",
    "        Object.defineProperty(navigator, 'languages', {get: () => ['en-US', 'en']});\n",
    "        Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});\n",
    "        \"\"\"\n",
    "    })\n",
    "\n",
    "def scrape_products_from_category(driver, url):\n",
    "    driver.get(url)\n",
    "    accept_cookies(driver)\n",
    "    select_abholservice(driver)\n",
    "\n",
    "    products = []\n",
    "    page_num = 1\n",
    "\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 30)\n",
    "        wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"article.search-service-product\")))\n",
    "        time.sleep(2)\n",
    "        print(f\"[INFO] Scraping products on page {page_num}...\")\n",
    "\n",
    "        product_elements = driver.find_elements(By.CSS_SELECTOR, \"article.search-service-product\")\n",
    "\n",
    "        for el in product_elements:\n",
    "            try:\n",
    "                image_elem = el.find_element(By.TAG_NAME, \"img\")\n",
    "                name = image_elem.get_attribute(\"alt\").strip()\n",
    "                imageUrl = image_elem.get_attribute(\"src\")\n",
    "            except:\n",
    "                name = \"\"\n",
    "                imageUrl = \"\"\n",
    "\n",
    "            try:\n",
    "                price = el.find_element(By.CSS_SELECTOR, \"div.productPrice, .search-service-productPrice\").text.strip().replace(\"\\n\", \"\")\n",
    "            except:\n",
    "                price = \"\"\n",
    "\n",
    "            try:\n",
    "                unit = el.find_element(By.CSS_SELECTOR, \"div.productGrammage, .search-service-productGrammage\").text.strip()\n",
    "            except:\n",
    "                unit = \"\"\n",
    "\n",
    "            products.append({\"name\": name, \"price\": price, \"unit\": unit, \"imageUrl\": imageUrl})\n",
    "\n",
    "        print(f\"[INFO] Found {len(product_elements)} products on page {page_num}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error scraping products: {e}\")\n",
    "\n",
    "    print(f\"[INFO] Total products found: {len(products)}\")\n",
    "    return products\n",
    "\n",
    "def main():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    # Do NOT run headless because CAPTCHA needs manual solving\n",
    "    # options.add_argument(\"--headless\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.set_window_size(1920, 1080)\n",
    "    enable_stealth(driver)\n",
    "\n",
    "    links = read_links_from_file(\"links.txt\")\n",
    "    result = {}\n",
    "\n",
    "    if not links:\n",
    "        print(\"[ERROR] No links found in links.txt\")\n",
    "        return\n",
    "\n",
    "    first_url = links[0]\n",
    "    print(f\"[INFO] Setting PLZ and market on: {first_url}\")\n",
    "    driver.get(first_url)\n",
    "    accept_cookies(driver)\n",
    "    select_abholservice(driver)\n",
    "    enter_plz_and_select_market(driver)\n",
    "\n",
    "    print(\"[ACTION] If a CAPTCHA appears, please solve it manually in the browser.\")\n",
    "    input(\"Press Enter after solving the CAPTCHA to continue scraping...\")\n",
    "\n",
    "    for url in links:\n",
    "        category = extract_category(url)\n",
    "        print(f\"[INFO] Scraping category: {category} -> {url}\")\n",
    "        products = scrape_products_from_category(driver, url)\n",
    "        result[category] = products\n",
    "        print(f\"[INFO] {category}: {len(products)} products scraped.\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    with open(\"rewe-products-10115.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"[DONE] All products saved to rewe-products.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setting PLZ and market on: https://shop.rewe.de/c/olivenoel/?search=oliven%C3%B6l\n",
      "[INFO] Abholservice selected.\n",
      "[WARN] Failed to enter PLZ.\n",
      "[INFO] Abholmarkt selected.\n",
      "[ACTION] If a CAPTCHA appears, please solve it manually in the browser.\n",
      "[INFO] Scraping category: olivenoel -> https://shop.rewe.de/c/olivenoel/?search=oliven%C3%B6l\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 19 products on page 1.\n",
      "[INFO] Total products found: 19\n",
      "[INFO] olivenoel: 19 products scraped.\n",
      "[INFO] Scraping category: sossen -> https://shop.rewe.de/c/sossen/?search=pesto\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 24 products on page 1.\n",
      "[INFO] Total products found: 24\n",
      "[INFO] sossen: 24 products scraped.\n",
      "[INFO] Scraping category: tee -> https://shop.rewe.de/c/tee/?objectsPerPage=80&search=tee\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 80 products on page 1.\n",
      "[INFO] Total products found: 80\n",
      "[INFO] tee: 80 products scraped.\n",
      "[INFO] Scraping category: tee -> https://shop.rewe.de/c/tee/?objectsPerPage=80&page=2&search=tee\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 26 products on page 1.\n",
      "[INFO] Total products found: 26\n",
      "[INFO] tee: 26 products scraped.\n",
      "[INFO] Scraping category: cola -> https://shop.rewe.de/c/cola/?brand=Coca-Cola&objectsPerPage=80&search=cola\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 49 products on page 1.\n",
      "[INFO] Total products found: 49\n",
      "[INFO] cola: 49 products scraped.\n",
      "[INFO] Scraping category: https://shop.rewe.de/productList?objectsPerPage=80&search=kartoffelchips -> https://shop.rewe.de/productList?objectsPerPage=80&search=kartoffelchips\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 51 products on page 1.\n",
      "[INFO] Total products found: 51\n",
      "[INFO] https://shop.rewe.de/productList?objectsPerPage=80&search=kartoffelchips: 51 products scraped.\n",
      "[INFO] Scraping category: https://shop.rewe.de/productList?search=alufolie -> https://shop.rewe.de/productList?search=alufolie\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 2 products on page 1.\n",
      "[INFO] Total products found: 2\n",
      "[INFO] https://shop.rewe.de/productList?search=alufolie: 2 products scraped.\n",
      "[INFO] Scraping category: toilettenpapier -> https://shop.rewe.de/c/toilettenpapier/?search=toilettenpapier\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 23 products on page 1.\n",
      "[INFO] Total products found: 23\n",
      "[INFO] toilettenpapier: 23 products scraped.\n",
      "[INFO] Scraping category: https://shop.rewe.de/productList?objectsPerPage=80&search=waschmittel -> https://shop.rewe.de/productList?objectsPerPage=80&search=waschmittel\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 28 products on page 1.\n",
      "[INFO] Total products found: 28\n",
      "[INFO] https://shop.rewe.de/productList?objectsPerPage=80&search=waschmittel: 28 products scraped.\n",
      "[INFO] Scraping category: reis -> https://shop.rewe.de/c/reis/?objectsPerPage=80&search=reis\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 54 products on page 1.\n",
      "[INFO] Total products found: 54\n",
      "[INFO] reis: 54 products scraped.\n",
      "[INFO] Scraping category: sossen -> https://shop.rewe.de/c/sossen/?search=mayonnaise\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 21 products on page 1.\n",
      "[INFO] Total products found: 21\n",
      "[INFO] sossen: 21 products scraped.\n",
      "[INFO] Scraping category: sossen -> https://shop.rewe.de/c/sossen/?search=ketchup\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 19 products on page 1.\n",
      "[INFO] Total products found: 19\n",
      "[INFO] sossen: 19 products scraped.\n",
      "[INFO] Scraping category: nudeln -> https://shop.rewe.de/c/nudeln/?search=spaghetti\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 18 products on page 1.\n",
      "[INFO] Total products found: 18\n",
      "[INFO] nudeln: 18 products scraped.\n",
      "[INFO] Scraping category: eier-ei-ersatz -> https://shop.rewe.de/c/eier-ei-ersatz/?search=eier\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 15 products on page 1.\n",
      "[INFO] Total products found: 15\n",
      "[INFO] eier-ei-ersatz: 15 products scraped.\n",
      "[INFO] Scraping category: frischmilch -> https://shop.rewe.de/c/frischmilch/?objectsPerPage=80&search=milch\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 15 products on page 1.\n",
      "[INFO] Total products found: 15\n",
      "[INFO] frischmilch: 15 products scraped.\n",
      "[DONE] All products saved to rewe-products.json\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "\n",
    "def extract_category(url: str) -> str:\n",
    "    match = re.search(r\"/c/([^/?]+)\", url)\n",
    "    return match.group(1) if match else url\n",
    "\n",
    "def read_links_from_file(file_path: str):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def accept_cookies(driver):\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        buttons = wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, \"button\")))\n",
    "        for btn in buttons:\n",
    "            if \"alle erlauben\" in btn.text.lower():\n",
    "                btn.click()\n",
    "                print(\"[INFO] Cookies accepted.\")\n",
    "                time.sleep(2)\n",
    "                return\n",
    "    except Exception:\n",
    "        print(\"[INFO] No cookie modal or already accepted.\")\n",
    "\n",
    "def select_abholservice(driver):\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        buttons = wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, \"button\")))\n",
    "        for btn in buttons:\n",
    "            if \"abholservice\" in btn.text.lower():\n",
    "                btn.click()\n",
    "                print(\"[INFO] Abholservice selected.\")\n",
    "                time.sleep(2)\n",
    "                return\n",
    "    except Exception:\n",
    "        print(\"[INFO] No Abholservice modal or already handled.\")\n",
    "\n",
    "def enter_plz_and_select_market(driver):\n",
    "    try:\n",
    "        time.sleep(2)\n",
    "        plz_input = driver.find_element(By.TAG_NAME, \"input\")\n",
    "        plz_input.clear()\n",
    "        plz_input.send_keys(\"10117\")\n",
    "        plz_input.submit()\n",
    "        print(\"[INFO] PLZ entered and submitted.\")\n",
    "        time.sleep(3)\n",
    "    except Exception:\n",
    "        print(\"[WARN] Failed to enter PLZ.\")\n",
    "\n",
    "    try:\n",
    "        for _ in range(20):\n",
    "            buttons = driver.find_elements(By.TAG_NAME, \"button\")\n",
    "            for btn in buttons:\n",
    "                if \"abholmarkt wÃ¤hlen\" in btn.text.lower():\n",
    "                    btn.click()\n",
    "                    print(\"[INFO] Abholmarkt selected.\")\n",
    "                    time.sleep(3)\n",
    "                    return\n",
    "            time.sleep(1)\n",
    "        print(\"[WARN] No 'Abholmarkt wÃ¤hlen' button found.\")\n",
    "    except Exception:\n",
    "        print(\"[ERROR] Error selecting Abholmarkt.\")\n",
    "\n",
    "def enable_stealth(driver):\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "        \"source\": \"\"\"\n",
    "        Object.defineProperty(navigator, 'webdriver', {get: () => undefined});\n",
    "        Object.defineProperty(navigator, 'languages', {get: () => ['en-US', 'en']});\n",
    "        Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});\n",
    "        \"\"\"\n",
    "    })\n",
    "\n",
    "def scrape_products_from_category(driver, url):\n",
    "    driver.get(url)\n",
    "    accept_cookies(driver)\n",
    "    select_abholservice(driver)\n",
    "\n",
    "    products = []\n",
    "    page_num = 1\n",
    "\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 30)\n",
    "        wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"article.search-service-product\")))\n",
    "        time.sleep(2)\n",
    "        print(f\"[INFO] Scraping products on page {page_num}...\")\n",
    "\n",
    "        product_elements = driver.find_elements(By.CSS_SELECTOR, \"article.search-service-product\")\n",
    "\n",
    "        for el in product_elements:\n",
    "            try:\n",
    "                image_elem = el.find_element(By.TAG_NAME, \"img\")\n",
    "                name = image_elem.get_attribute(\"alt\").strip()\n",
    "                imageUrl = image_elem.get_attribute(\"src\")\n",
    "            except:\n",
    "                name = \"\"\n",
    "                imageUrl = \"\"\n",
    "\n",
    "            try:\n",
    "                price = el.find_element(By.CSS_SELECTOR, \"div.productPrice, .search-service-productPrice\").text.strip().replace(\"\\n\", \"\")\n",
    "            except:\n",
    "                price = \"\"\n",
    "\n",
    "            try:\n",
    "                unit = el.find_element(By.CSS_SELECTOR, \"div.productGrammage, .search-service-productGrammage\").text.strip()\n",
    "            except:\n",
    "                unit = \"\"\n",
    "\n",
    "            products.append({\"name\": name, \"price\": price, \"unit\": unit, \"imageUrl\": imageUrl})\n",
    "\n",
    "        print(f\"[INFO] Found {len(product_elements)} products on page {page_num}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error scraping products: {e}\")\n",
    "\n",
    "    print(f\"[INFO] Total products found: {len(products)}\")\n",
    "    return products\n",
    "\n",
    "def main():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    # Do NOT run headless because CAPTCHA needs manual solving\n",
    "    # options.add_argument(\"--headless\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.set_window_size(1920, 1080)\n",
    "    enable_stealth(driver)\n",
    "\n",
    "    links = read_links_from_file(\"links.txt\")\n",
    "    result = {}\n",
    "\n",
    "    if not links:\n",
    "        print(\"[ERROR] No links found in links.txt\")\n",
    "        return\n",
    "\n",
    "    first_url = links[0]\n",
    "    print(f\"[INFO] Setting PLZ and market on: {first_url}\")\n",
    "    driver.get(first_url)\n",
    "    accept_cookies(driver)\n",
    "    select_abholservice(driver)\n",
    "    enter_plz_and_select_market(driver)\n",
    "\n",
    "    print(\"[ACTION] If a CAPTCHA appears, please solve it manually in the browser.\")\n",
    "    input(\"Press Enter after solving the CAPTCHA to continue scraping...\")\n",
    "\n",
    "    for url in links:\n",
    "        category = extract_category(url)\n",
    "        print(f\"[INFO] Scraping category: {category} -> {url}\")\n",
    "        products = scrape_products_from_category(driver, url)\n",
    "        result[category] = products\n",
    "        print(f\"[INFO] {category}: {len(products)} products scraped.\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    with open(\"rewe-products-10117.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"[DONE] All products saved to rewe-products.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setting PLZ and market on: https://shop.rewe.de/c/olivenoel/?search=oliven%C3%B6l\n",
      "[INFO] Abholservice selected.\n",
      "[WARN] Failed to enter PLZ.\n",
      "[INFO] Abholmarkt selected.\n",
      "[ACTION] If a CAPTCHA appears, please solve it manually in the browser.\n",
      "[INFO] Scraping category: olivenoel -> https://shop.rewe.de/c/olivenoel/?search=oliven%C3%B6l\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 22 products on page 1.\n",
      "[INFO] Total products found: 22\n",
      "[INFO] olivenoel: 22 products scraped.\n",
      "[INFO] Scraping category: sossen -> https://shop.rewe.de/c/sossen/?search=pesto\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 40 products on page 1.\n",
      "[INFO] Total products found: 40\n",
      "[INFO] sossen: 40 products scraped.\n",
      "[INFO] Scraping category: tee -> https://shop.rewe.de/c/tee/?objectsPerPage=80&search=tee\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 80 products on page 1.\n",
      "[INFO] Total products found: 80\n",
      "[INFO] tee: 80 products scraped.\n",
      "[INFO] Scraping category: tee -> https://shop.rewe.de/c/tee/?objectsPerPage=80&page=2&search=tee\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 80 products on page 1.\n",
      "[INFO] Total products found: 80\n",
      "[INFO] tee: 80 products scraped.\n",
      "[INFO] Scraping category: cola -> https://shop.rewe.de/c/cola/?brand=Coca-Cola&objectsPerPage=80&search=cola\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 54 products on page 1.\n",
      "[INFO] Total products found: 54\n",
      "[INFO] cola: 54 products scraped.\n",
      "[INFO] Scraping category: https://shop.rewe.de/productList?objectsPerPage=80&search=kartoffelchips -> https://shop.rewe.de/productList?objectsPerPage=80&search=kartoffelchips\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 64 products on page 1.\n",
      "[INFO] Total products found: 64\n",
      "[INFO] https://shop.rewe.de/productList?objectsPerPage=80&search=kartoffelchips: 64 products scraped.\n",
      "[INFO] Scraping category: https://shop.rewe.de/productList?search=alufolie -> https://shop.rewe.de/productList?search=alufolie\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 3 products on page 1.\n",
      "[INFO] Total products found: 3\n",
      "[INFO] https://shop.rewe.de/productList?search=alufolie: 3 products scraped.\n",
      "[INFO] Scraping category: toilettenpapier -> https://shop.rewe.de/c/toilettenpapier/?search=toilettenpapier\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 32 products on page 1.\n",
      "[INFO] Total products found: 32\n",
      "[INFO] toilettenpapier: 32 products scraped.\n",
      "[INFO] Scraping category: https://shop.rewe.de/productList?objectsPerPage=80&search=waschmittel -> https://shop.rewe.de/productList?objectsPerPage=80&search=waschmittel\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 77 products on page 1.\n",
      "[INFO] Total products found: 77\n",
      "[INFO] https://shop.rewe.de/productList?objectsPerPage=80&search=waschmittel: 77 products scraped.\n",
      "[INFO] Scraping category: reis -> https://shop.rewe.de/c/reis/?objectsPerPage=80&search=reis\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 78 products on page 1.\n",
      "[INFO] Total products found: 78\n",
      "[INFO] reis: 78 products scraped.\n",
      "[INFO] Scraping category: sossen -> https://shop.rewe.de/c/sossen/?search=mayonnaise\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 34 products on page 1.\n",
      "[INFO] Total products found: 34\n",
      "[INFO] sossen: 34 products scraped.\n",
      "[INFO] Scraping category: sossen -> https://shop.rewe.de/c/sossen/?search=ketchup\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 38 products on page 1.\n",
      "[INFO] Total products found: 38\n",
      "[INFO] sossen: 38 products scraped.\n",
      "[INFO] Scraping category: nudeln -> https://shop.rewe.de/c/nudeln/?search=spaghetti\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 31 products on page 1.\n",
      "[INFO] Total products found: 31\n",
      "[INFO] nudeln: 31 products scraped.\n",
      "[INFO] Scraping category: eier-ei-ersatz -> https://shop.rewe.de/c/eier-ei-ersatz/?search=eier\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 22 products on page 1.\n",
      "[INFO] Total products found: 22\n",
      "[INFO] eier-ei-ersatz: 22 products scraped.\n",
      "[INFO] Scraping category: frischmilch -> https://shop.rewe.de/c/frischmilch/?objectsPerPage=80&search=milch\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 25 products on page 1.\n",
      "[INFO] Total products found: 25\n",
      "[INFO] frischmilch: 25 products scraped.\n",
      "[DONE] All products saved to rewe-products.json\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "\n",
    "def extract_category(url: str) -> str:\n",
    "    match = re.search(r\"/c/([^/?]+)\", url)\n",
    "    return match.group(1) if match else url\n",
    "\n",
    "def read_links_from_file(file_path: str):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def accept_cookies(driver):\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        buttons = wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, \"button\")))\n",
    "        for btn in buttons:\n",
    "            if \"alle erlauben\" in btn.text.lower():\n",
    "                btn.click()\n",
    "                print(\"[INFO] Cookies accepted.\")\n",
    "                time.sleep(2)\n",
    "                return\n",
    "    except Exception:\n",
    "        print(\"[INFO] No cookie modal or already accepted.\")\n",
    "\n",
    "def select_abholservice(driver):\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        buttons = wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, \"button\")))\n",
    "        for btn in buttons:\n",
    "            if \"abholservice\" in btn.text.lower():\n",
    "                btn.click()\n",
    "                print(\"[INFO] Abholservice selected.\")\n",
    "                time.sleep(2)\n",
    "                return\n",
    "    except Exception:\n",
    "        print(\"[INFO] No Abholservice modal or already handled.\")\n",
    "\n",
    "def enter_plz_and_select_market(driver):\n",
    "    try:\n",
    "        time.sleep(2)\n",
    "        plz_input = driver.find_element(By.TAG_NAME, \"input\")\n",
    "        plz_input.clear()\n",
    "        plz_input.send_keys(\"10119\")\n",
    "        plz_input.submit()\n",
    "        print(\"[INFO] PLZ entered and submitted.\")\n",
    "        time.sleep(3)\n",
    "    except Exception:\n",
    "        print(\"[WARN] Failed to enter PLZ.\")\n",
    "\n",
    "    try:\n",
    "        for _ in range(20):\n",
    "            buttons = driver.find_elements(By.TAG_NAME, \"button\")\n",
    "            for btn in buttons:\n",
    "                if \"abholmarkt wÃ¤hlen\" in btn.text.lower():\n",
    "                    btn.click()\n",
    "                    print(\"[INFO] Abholmarkt selected.\")\n",
    "                    time.sleep(3)\n",
    "                    return\n",
    "            time.sleep(1)\n",
    "        print(\"[WARN] No 'Abholmarkt wÃ¤hlen' button found.\")\n",
    "    except Exception:\n",
    "        print(\"[ERROR] Error selecting Abholmarkt.\")\n",
    "\n",
    "def enable_stealth(driver):\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "        \"source\": \"\"\"\n",
    "        Object.defineProperty(navigator, 'webdriver', {get: () => undefined});\n",
    "        Object.defineProperty(navigator, 'languages', {get: () => ['en-US', 'en']});\n",
    "        Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});\n",
    "        \"\"\"\n",
    "    })\n",
    "\n",
    "def scrape_products_from_category(driver, url):\n",
    "    driver.get(url)\n",
    "    accept_cookies(driver)\n",
    "    select_abholservice(driver)\n",
    "\n",
    "    products = []\n",
    "    page_num = 1\n",
    "\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 30)\n",
    "        wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"article.search-service-product\")))\n",
    "        time.sleep(2)\n",
    "        print(f\"[INFO] Scraping products on page {page_num}...\")\n",
    "\n",
    "        product_elements = driver.find_elements(By.CSS_SELECTOR, \"article.search-service-product\")\n",
    "\n",
    "        for el in product_elements:\n",
    "            try:\n",
    "                image_elem = el.find_element(By.TAG_NAME, \"img\")\n",
    "                name = image_elem.get_attribute(\"alt\").strip()\n",
    "                imageUrl = image_elem.get_attribute(\"src\")\n",
    "            except:\n",
    "                name = \"\"\n",
    "                imageUrl = \"\"\n",
    "\n",
    "            try:\n",
    "                price = el.find_element(By.CSS_SELECTOR, \"div.productPrice, .search-service-productPrice\").text.strip().replace(\"\\n\", \"\")\n",
    "            except:\n",
    "                price = \"\"\n",
    "\n",
    "            try:\n",
    "                unit = el.find_element(By.CSS_SELECTOR, \"div.productGrammage, .search-service-productGrammage\").text.strip()\n",
    "            except:\n",
    "                unit = \"\"\n",
    "\n",
    "            products.append({\"name\": name, \"price\": price, \"unit\": unit, \"imageUrl\": imageUrl})\n",
    "\n",
    "        print(f\"[INFO] Found {len(product_elements)} products on page {page_num}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error scraping products: {e}\")\n",
    "\n",
    "    print(f\"[INFO] Total products found: {len(products)}\")\n",
    "    return products\n",
    "\n",
    "def main():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    # Do NOT run headless because CAPTCHA needs manual solving\n",
    "    # options.add_argument(\"--headless\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.set_window_size(1920, 1080)\n",
    "    enable_stealth(driver)\n",
    "\n",
    "    links = read_links_from_file(\"links.txt\")\n",
    "    result = {}\n",
    "\n",
    "    if not links:\n",
    "        print(\"[ERROR] No links found in links.txt\")\n",
    "        return\n",
    "\n",
    "    first_url = links[0]\n",
    "    print(f\"[INFO] Setting PLZ and market on: {first_url}\")\n",
    "    driver.get(first_url)\n",
    "    accept_cookies(driver)\n",
    "    select_abholservice(driver)\n",
    "    enter_plz_and_select_market(driver)\n",
    "\n",
    "    print(\"[ACTION] If a CAPTCHA appears, please solve it manually in the browser.\")\n",
    "    input(\"Press Enter after solving the CAPTCHA to continue scraping...\")\n",
    "\n",
    "    for url in links:\n",
    "        category = extract_category(url)\n",
    "        print(f\"[INFO] Scraping category: {category} -> {url}\")\n",
    "        products = scrape_products_from_category(driver, url)\n",
    "        result[category] = products\n",
    "        print(f\"[INFO] {category}: {len(products)} products scraped.\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    with open(\"rewe-products-10119.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"[DONE] All products saved to rewe-products.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
