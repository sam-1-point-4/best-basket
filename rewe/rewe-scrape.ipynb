{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zip 10115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setting PLZ and market on: https://shop.rewe.de/c/olivenoel/?search=oliven%C3%B6l\n",
      "[INFO] Abholservice selected.\n",
      "[WARN] Failed to enter PLZ.\n",
      "[INFO] Abholmarkt selected.\n",
      "[ACTION] If a CAPTCHA appears, please solve it manually in the browser.\n",
      "[INFO] Scraping category: olivenoel -> https://shop.rewe.de/c/olivenoel/?search=oliven%C3%B6l\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 30 products on page 1.\n",
      "[INFO] Total products found: 30\n",
      "[INFO] olivenoel: 30 products scraped.\n",
      "[INFO] Scraping category: sossen -> https://shop.rewe.de/c/sossen/?search=pesto\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 36 products on page 1.\n",
      "[INFO] Total products found: 36\n",
      "[INFO] sossen: 36 products scraped.\n",
      "[INFO] Scraping category: tee -> https://shop.rewe.de/c/tee/?objectsPerPage=80&search=tee\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 80 products on page 1.\n",
      "[INFO] Total products found: 80\n",
      "[INFO] tee: 80 products scraped.\n",
      "[INFO] Scraping category: tee -> https://shop.rewe.de/c/tee/?objectsPerPage=80&page=2&search=tee\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 80 products on page 1.\n",
      "[INFO] Total products found: 80\n",
      "[INFO] tee: 80 products scraped.\n",
      "[INFO] Scraping category: cola -> https://shop.rewe.de/c/cola/?brand=Coca-Cola&objectsPerPage=80&search=cola\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 52 products on page 1.\n",
      "[INFO] Total products found: 52\n",
      "[INFO] cola: 52 products scraped.\n",
      "[INFO] Scraping category: https://shop.rewe.de/productList?objectsPerPage=80&search=kartoffelchips -> https://shop.rewe.de/productList?objectsPerPage=80&search=kartoffelchips\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 82 products on page 1.\n",
      "[INFO] Total products found: 82\n",
      "[INFO] https://shop.rewe.de/productList?objectsPerPage=80&search=kartoffelchips: 82 products scraped.\n",
      "[INFO] Scraping category: https://shop.rewe.de/productList?search=alufolie -> https://shop.rewe.de/productList?search=alufolie\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 3 products on page 1.\n",
      "[INFO] Total products found: 3\n",
      "[INFO] https://shop.rewe.de/productList?search=alufolie: 3 products scraped.\n",
      "[INFO] Scraping category: toilettenpapier -> https://shop.rewe.de/c/toilettenpapier/?search=toilettenpapier\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 30 products on page 1.\n",
      "[INFO] Total products found: 30\n",
      "[INFO] toilettenpapier: 30 products scraped.\n",
      "[INFO] Scraping category: https://shop.rewe.de/productList?objectsPerPage=80&search=waschmittel -> https://shop.rewe.de/productList?objectsPerPage=80&search=waschmittel\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 75 products on page 1.\n",
      "[INFO] Total products found: 75\n",
      "[INFO] https://shop.rewe.de/productList?objectsPerPage=80&search=waschmittel: 75 products scraped.\n",
      "[INFO] Scraping category: reis -> https://shop.rewe.de/c/reis/?objectsPerPage=80&search=reis\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 75 products on page 1.\n",
      "[INFO] Total products found: 75\n",
      "[INFO] reis: 75 products scraped.\n",
      "[INFO] Scraping category: sossen -> https://shop.rewe.de/c/sossen/?search=mayonnaise\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 33 products on page 1.\n",
      "[INFO] Total products found: 33\n",
      "[INFO] sossen: 33 products scraped.\n",
      "[INFO] Scraping category: sossen -> https://shop.rewe.de/c/sossen/?search=ketchup\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 35 products on page 1.\n",
      "[INFO] Total products found: 35\n",
      "[INFO] sossen: 35 products scraped.\n",
      "[INFO] Scraping category: nudeln -> https://shop.rewe.de/c/nudeln/?search=spaghetti\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 31 products on page 1.\n",
      "[INFO] Total products found: 31\n",
      "[INFO] nudeln: 31 products scraped.\n",
      "[INFO] Scraping category: eier-ei-ersatz -> https://shop.rewe.de/c/eier-ei-ersatz/?search=eier\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 19 products on page 1.\n",
      "[INFO] Total products found: 19\n",
      "[INFO] eier-ei-ersatz: 19 products scraped.\n",
      "[INFO] Scraping category: frischmilch -> https://shop.rewe.de/c/frischmilch/?objectsPerPage=80&search=milch\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 19 products on page 1.\n",
      "[INFO] Total products found: 19\n",
      "[INFO] frischmilch: 19 products scraped.\n",
      "[DONE] All products saved to rewe-products.json\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "\n",
    "def extract_category(url: str) -> str:\n",
    "    match = re.search(r\"/c/([^/?]+)\", url)\n",
    "    return match.group(1) if match else url\n",
    "\n",
    "def read_links_from_file(file_path: str):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def accept_cookies(driver):\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        buttons = wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, \"button\")))\n",
    "        for btn in buttons:\n",
    "            if \"alle erlauben\" in btn.text.lower():\n",
    "                btn.click()\n",
    "                print(\"[INFO] Cookies accepted.\")\n",
    "                time.sleep(2)\n",
    "                return\n",
    "    except Exception:\n",
    "        print(\"[INFO] No cookie modal or already accepted.\")\n",
    "\n",
    "def select_abholservice(driver):\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        buttons = wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, \"button\")))\n",
    "        for btn in buttons:\n",
    "            if \"abholservice\" in btn.text.lower():\n",
    "                btn.click()\n",
    "                print(\"[INFO] Abholservice selected.\")\n",
    "                time.sleep(2)\n",
    "                return\n",
    "    except Exception:\n",
    "        print(\"[INFO] No Abholservice modal or already handled.\")\n",
    "\n",
    "def enter_plz_and_select_market(driver):\n",
    "    try:\n",
    "        time.sleep(2)\n",
    "        plz_input = driver.find_element(By.TAG_NAME, \"input\")\n",
    "        plz_input.clear()\n",
    "        plz_input.send_keys(\"10115\")\n",
    "        plz_input.submit()\n",
    "        print(\"[INFO] PLZ entered and submitted.\")\n",
    "        time.sleep(3)\n",
    "    except Exception:\n",
    "        print(\"[WARN] Failed to enter PLZ.\")\n",
    "\n",
    "    try:\n",
    "        for _ in range(20):\n",
    "            buttons = driver.find_elements(By.TAG_NAME, \"button\")\n",
    "            for btn in buttons:\n",
    "                if \"abholmarkt wählen\" in btn.text.lower():\n",
    "                    btn.click()\n",
    "                    print(\"[INFO] Abholmarkt selected.\")\n",
    "                    time.sleep(3)\n",
    "                    return\n",
    "            time.sleep(1)\n",
    "        print(\"[WARN] No 'Abholmarkt wählen' button found.\")\n",
    "    except Exception:\n",
    "        print(\"[ERROR] Error selecting Abholmarkt.\")\n",
    "\n",
    "def enable_stealth(driver):\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "        \"source\": \"\"\"\n",
    "        Object.defineProperty(navigator, 'webdriver', {get: () => undefined});\n",
    "        Object.defineProperty(navigator, 'languages', {get: () => ['en-US', 'en']});\n",
    "        Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});\n",
    "        \"\"\"\n",
    "    })\n",
    "\n",
    "def scrape_products_from_category(driver, url):\n",
    "    driver.get(url)\n",
    "    accept_cookies(driver)\n",
    "    select_abholservice(driver)\n",
    "\n",
    "    products = []\n",
    "    page_num = 1\n",
    "\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 30)\n",
    "        wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"article.search-service-product\")))\n",
    "        time.sleep(2)\n",
    "        print(f\"[INFO] Scraping products on page {page_num}...\")\n",
    "\n",
    "        product_elements = driver.find_elements(By.CSS_SELECTOR, \"article.search-service-product\")\n",
    "\n",
    "        for el in product_elements:\n",
    "            try:\n",
    "                image_elem = el.find_element(By.TAG_NAME, \"img\")\n",
    "                name = image_elem.get_attribute(\"alt\").strip()\n",
    "                imageUrl = image_elem.get_attribute(\"src\")\n",
    "            except:\n",
    "                name = \"\"\n",
    "                imageUrl = \"\"\n",
    "\n",
    "            try:\n",
    "                price = el.find_element(By.CSS_SELECTOR, \"div.productPrice, .search-service-productPrice\").text.strip().replace(\"\\n\", \"\")\n",
    "            except:\n",
    "                price = \"\"\n",
    "\n",
    "            try:\n",
    "                unit = el.find_element(By.CSS_SELECTOR, \"div.productGrammage, .search-service-productGrammage\").text.strip()\n",
    "            except:\n",
    "                unit = \"\"\n",
    "\n",
    "            products.append({\"name\": name, \"price\": price, \"unit\": unit, \"imageUrl\": imageUrl})\n",
    "\n",
    "        print(f\"[INFO] Found {len(product_elements)} products on page {page_num}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error scraping products: {e}\")\n",
    "\n",
    "    print(f\"[INFO] Total products found: {len(products)}\")\n",
    "    return products\n",
    "\n",
    "def main():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    # Do NOT run headless because CAPTCHA needs manual solving\n",
    "    # options.add_argument(\"--headless\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.set_window_size(1920, 1080)\n",
    "    enable_stealth(driver)\n",
    "\n",
    "    links = read_links_from_file(\"links.txt\")\n",
    "    result = {}\n",
    "\n",
    "    if not links:\n",
    "        print(\"[ERROR] No links found in links.txt\")\n",
    "        return\n",
    "\n",
    "    first_url = links[0]\n",
    "    print(f\"[INFO] Setting PLZ and market on: {first_url}\")\n",
    "    driver.get(first_url)\n",
    "    accept_cookies(driver)\n",
    "    select_abholservice(driver)\n",
    "    enter_plz_and_select_market(driver)\n",
    "\n",
    "    print(\"[ACTION] If a CAPTCHA appears, please solve it manually in the browser.\")\n",
    "    input(\"Press Enter after solving the CAPTCHA to continue scraping...\")\n",
    "\n",
    "    for url in links:\n",
    "        category = extract_category(url)\n",
    "        print(f\"[INFO] Scraping category: {category} -> {url}\")\n",
    "        products = scrape_products_from_category(driver, url)\n",
    "        result[category] = products\n",
    "        print(f\"[INFO] {category}: {len(products)} products scraped.\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    with open(\"rewe-products-10115.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"[DONE] All products saved to rewe-products.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setting PLZ and market on: https://shop.rewe.de/c/olivenoel/?search=oliven%C3%B6l\n",
      "[INFO] Abholservice selected.\n",
      "[WARN] Failed to enter PLZ.\n",
      "[INFO] Abholmarkt selected.\n",
      "[ACTION] If a CAPTCHA appears, please solve it manually in the browser.\n",
      "[INFO] Scraping category: olivenoel -> https://shop.rewe.de/c/olivenoel/?search=oliven%C3%B6l\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 19 products on page 1.\n",
      "[INFO] Total products found: 19\n",
      "[INFO] olivenoel: 19 products scraped.\n",
      "[INFO] Scraping category: sossen -> https://shop.rewe.de/c/sossen/?search=pesto\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 24 products on page 1.\n",
      "[INFO] Total products found: 24\n",
      "[INFO] sossen: 24 products scraped.\n",
      "[INFO] Scraping category: tee -> https://shop.rewe.de/c/tee/?objectsPerPage=80&search=tee\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 80 products on page 1.\n",
      "[INFO] Total products found: 80\n",
      "[INFO] tee: 80 products scraped.\n",
      "[INFO] Scraping category: tee -> https://shop.rewe.de/c/tee/?objectsPerPage=80&page=2&search=tee\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 26 products on page 1.\n",
      "[INFO] Total products found: 26\n",
      "[INFO] tee: 26 products scraped.\n",
      "[INFO] Scraping category: cola -> https://shop.rewe.de/c/cola/?brand=Coca-Cola&objectsPerPage=80&search=cola\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 49 products on page 1.\n",
      "[INFO] Total products found: 49\n",
      "[INFO] cola: 49 products scraped.\n",
      "[INFO] Scraping category: https://shop.rewe.de/productList?objectsPerPage=80&search=kartoffelchips -> https://shop.rewe.de/productList?objectsPerPage=80&search=kartoffelchips\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 51 products on page 1.\n",
      "[INFO] Total products found: 51\n",
      "[INFO] https://shop.rewe.de/productList?objectsPerPage=80&search=kartoffelchips: 51 products scraped.\n",
      "[INFO] Scraping category: https://shop.rewe.de/productList?search=alufolie -> https://shop.rewe.de/productList?search=alufolie\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 2 products on page 1.\n",
      "[INFO] Total products found: 2\n",
      "[INFO] https://shop.rewe.de/productList?search=alufolie: 2 products scraped.\n",
      "[INFO] Scraping category: toilettenpapier -> https://shop.rewe.de/c/toilettenpapier/?search=toilettenpapier\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 23 products on page 1.\n",
      "[INFO] Total products found: 23\n",
      "[INFO] toilettenpapier: 23 products scraped.\n",
      "[INFO] Scraping category: https://shop.rewe.de/productList?objectsPerPage=80&search=waschmittel -> https://shop.rewe.de/productList?objectsPerPage=80&search=waschmittel\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 28 products on page 1.\n",
      "[INFO] Total products found: 28\n",
      "[INFO] https://shop.rewe.de/productList?objectsPerPage=80&search=waschmittel: 28 products scraped.\n",
      "[INFO] Scraping category: reis -> https://shop.rewe.de/c/reis/?objectsPerPage=80&search=reis\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 54 products on page 1.\n",
      "[INFO] Total products found: 54\n",
      "[INFO] reis: 54 products scraped.\n",
      "[INFO] Scraping category: sossen -> https://shop.rewe.de/c/sossen/?search=mayonnaise\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 21 products on page 1.\n",
      "[INFO] Total products found: 21\n",
      "[INFO] sossen: 21 products scraped.\n",
      "[INFO] Scraping category: sossen -> https://shop.rewe.de/c/sossen/?search=ketchup\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 19 products on page 1.\n",
      "[INFO] Total products found: 19\n",
      "[INFO] sossen: 19 products scraped.\n",
      "[INFO] Scraping category: nudeln -> https://shop.rewe.de/c/nudeln/?search=spaghetti\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 18 products on page 1.\n",
      "[INFO] Total products found: 18\n",
      "[INFO] nudeln: 18 products scraped.\n",
      "[INFO] Scraping category: eier-ei-ersatz -> https://shop.rewe.de/c/eier-ei-ersatz/?search=eier\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 15 products on page 1.\n",
      "[INFO] Total products found: 15\n",
      "[INFO] eier-ei-ersatz: 15 products scraped.\n",
      "[INFO] Scraping category: frischmilch -> https://shop.rewe.de/c/frischmilch/?objectsPerPage=80&search=milch\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 15 products on page 1.\n",
      "[INFO] Total products found: 15\n",
      "[INFO] frischmilch: 15 products scraped.\n",
      "[DONE] All products saved to rewe-products.json\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "\n",
    "def extract_category(url: str) -> str:\n",
    "    match = re.search(r\"/c/([^/?]+)\", url)\n",
    "    return match.group(1) if match else url\n",
    "\n",
    "def read_links_from_file(file_path: str):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def accept_cookies(driver):\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        buttons = wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, \"button\")))\n",
    "        for btn in buttons:\n",
    "            if \"alle erlauben\" in btn.text.lower():\n",
    "                btn.click()\n",
    "                print(\"[INFO] Cookies accepted.\")\n",
    "                time.sleep(2)\n",
    "                return\n",
    "    except Exception:\n",
    "        print(\"[INFO] No cookie modal or already accepted.\")\n",
    "\n",
    "def select_abholservice(driver):\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        buttons = wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, \"button\")))\n",
    "        for btn in buttons:\n",
    "            if \"abholservice\" in btn.text.lower():\n",
    "                btn.click()\n",
    "                print(\"[INFO] Abholservice selected.\")\n",
    "                time.sleep(2)\n",
    "                return\n",
    "    except Exception:\n",
    "        print(\"[INFO] No Abholservice modal or already handled.\")\n",
    "\n",
    "def enter_plz_and_select_market(driver):\n",
    "    try:\n",
    "        time.sleep(2)\n",
    "        plz_input = driver.find_element(By.TAG_NAME, \"input\")\n",
    "        plz_input.clear()\n",
    "        plz_input.send_keys(\"10117\")\n",
    "        plz_input.submit()\n",
    "        print(\"[INFO] PLZ entered and submitted.\")\n",
    "        time.sleep(3)\n",
    "    except Exception:\n",
    "        print(\"[WARN] Failed to enter PLZ.\")\n",
    "\n",
    "    try:\n",
    "        for _ in range(20):\n",
    "            buttons = driver.find_elements(By.TAG_NAME, \"button\")\n",
    "            for btn in buttons:\n",
    "                if \"abholmarkt wählen\" in btn.text.lower():\n",
    "                    btn.click()\n",
    "                    print(\"[INFO] Abholmarkt selected.\")\n",
    "                    time.sleep(3)\n",
    "                    return\n",
    "            time.sleep(1)\n",
    "        print(\"[WARN] No 'Abholmarkt wählen' button found.\")\n",
    "    except Exception:\n",
    "        print(\"[ERROR] Error selecting Abholmarkt.\")\n",
    "\n",
    "def enable_stealth(driver):\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "        \"source\": \"\"\"\n",
    "        Object.defineProperty(navigator, 'webdriver', {get: () => undefined});\n",
    "        Object.defineProperty(navigator, 'languages', {get: () => ['en-US', 'en']});\n",
    "        Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});\n",
    "        \"\"\"\n",
    "    })\n",
    "\n",
    "def scrape_products_from_category(driver, url):\n",
    "    driver.get(url)\n",
    "    accept_cookies(driver)\n",
    "    select_abholservice(driver)\n",
    "\n",
    "    products = []\n",
    "    page_num = 1\n",
    "\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 30)\n",
    "        wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"article.search-service-product\")))\n",
    "        time.sleep(2)\n",
    "        print(f\"[INFO] Scraping products on page {page_num}...\")\n",
    "\n",
    "        product_elements = driver.find_elements(By.CSS_SELECTOR, \"article.search-service-product\")\n",
    "\n",
    "        for el in product_elements:\n",
    "            try:\n",
    "                image_elem = el.find_element(By.TAG_NAME, \"img\")\n",
    "                name = image_elem.get_attribute(\"alt\").strip()\n",
    "                imageUrl = image_elem.get_attribute(\"src\")\n",
    "            except:\n",
    "                name = \"\"\n",
    "                imageUrl = \"\"\n",
    "\n",
    "            try:\n",
    "                price = el.find_element(By.CSS_SELECTOR, \"div.productPrice, .search-service-productPrice\").text.strip().replace(\"\\n\", \"\")\n",
    "            except:\n",
    "                price = \"\"\n",
    "\n",
    "            try:\n",
    "                unit = el.find_element(By.CSS_SELECTOR, \"div.productGrammage, .search-service-productGrammage\").text.strip()\n",
    "            except:\n",
    "                unit = \"\"\n",
    "\n",
    "            products.append({\"name\": name, \"price\": price, \"unit\": unit, \"imageUrl\": imageUrl})\n",
    "\n",
    "        print(f\"[INFO] Found {len(product_elements)} products on page {page_num}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error scraping products: {e}\")\n",
    "\n",
    "    print(f\"[INFO] Total products found: {len(products)}\")\n",
    "    return products\n",
    "\n",
    "def main():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    # Do NOT run headless because CAPTCHA needs manual solving\n",
    "    # options.add_argument(\"--headless\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.set_window_size(1920, 1080)\n",
    "    enable_stealth(driver)\n",
    "\n",
    "    links = read_links_from_file(\"links.txt\")\n",
    "    result = {}\n",
    "\n",
    "    if not links:\n",
    "        print(\"[ERROR] No links found in links.txt\")\n",
    "        return\n",
    "\n",
    "    first_url = links[0]\n",
    "    print(f\"[INFO] Setting PLZ and market on: {first_url}\")\n",
    "    driver.get(first_url)\n",
    "    accept_cookies(driver)\n",
    "    select_abholservice(driver)\n",
    "    enter_plz_and_select_market(driver)\n",
    "\n",
    "    print(\"[ACTION] If a CAPTCHA appears, please solve it manually in the browser.\")\n",
    "    input(\"Press Enter after solving the CAPTCHA to continue scraping...\")\n",
    "\n",
    "    for url in links:\n",
    "        category = extract_category(url)\n",
    "        print(f\"[INFO] Scraping category: {category} -> {url}\")\n",
    "        products = scrape_products_from_category(driver, url)\n",
    "        result[category] = products\n",
    "        print(f\"[INFO] {category}: {len(products)} products scraped.\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    with open(\"rewe-products-10117.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"[DONE] All products saved to rewe-products.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setting PLZ and market on: https://shop.rewe.de/c/olivenoel/?search=oliven%C3%B6l\n",
      "[INFO] Abholservice selected.\n",
      "[WARN] Failed to enter PLZ.\n",
      "[INFO] Abholmarkt selected.\n",
      "[ACTION] If a CAPTCHA appears, please solve it manually in the browser.\n",
      "[INFO] Scraping category: olivenoel -> https://shop.rewe.de/c/olivenoel/?search=oliven%C3%B6l\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 22 products on page 1.\n",
      "[INFO] Total products found: 22\n",
      "[INFO] olivenoel: 22 products scraped.\n",
      "[INFO] Scraping category: sossen -> https://shop.rewe.de/c/sossen/?search=pesto\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 40 products on page 1.\n",
      "[INFO] Total products found: 40\n",
      "[INFO] sossen: 40 products scraped.\n",
      "[INFO] Scraping category: tee -> https://shop.rewe.de/c/tee/?objectsPerPage=80&search=tee\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 80 products on page 1.\n",
      "[INFO] Total products found: 80\n",
      "[INFO] tee: 80 products scraped.\n",
      "[INFO] Scraping category: tee -> https://shop.rewe.de/c/tee/?objectsPerPage=80&page=2&search=tee\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 80 products on page 1.\n",
      "[INFO] Total products found: 80\n",
      "[INFO] tee: 80 products scraped.\n",
      "[INFO] Scraping category: cola -> https://shop.rewe.de/c/cola/?brand=Coca-Cola&objectsPerPage=80&search=cola\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 54 products on page 1.\n",
      "[INFO] Total products found: 54\n",
      "[INFO] cola: 54 products scraped.\n",
      "[INFO] Scraping category: https://shop.rewe.de/productList?objectsPerPage=80&search=kartoffelchips -> https://shop.rewe.de/productList?objectsPerPage=80&search=kartoffelchips\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 64 products on page 1.\n",
      "[INFO] Total products found: 64\n",
      "[INFO] https://shop.rewe.de/productList?objectsPerPage=80&search=kartoffelchips: 64 products scraped.\n",
      "[INFO] Scraping category: https://shop.rewe.de/productList?search=alufolie -> https://shop.rewe.de/productList?search=alufolie\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 3 products on page 1.\n",
      "[INFO] Total products found: 3\n",
      "[INFO] https://shop.rewe.de/productList?search=alufolie: 3 products scraped.\n",
      "[INFO] Scraping category: toilettenpapier -> https://shop.rewe.de/c/toilettenpapier/?search=toilettenpapier\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 32 products on page 1.\n",
      "[INFO] Total products found: 32\n",
      "[INFO] toilettenpapier: 32 products scraped.\n",
      "[INFO] Scraping category: https://shop.rewe.de/productList?objectsPerPage=80&search=waschmittel -> https://shop.rewe.de/productList?objectsPerPage=80&search=waschmittel\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 77 products on page 1.\n",
      "[INFO] Total products found: 77\n",
      "[INFO] https://shop.rewe.de/productList?objectsPerPage=80&search=waschmittel: 77 products scraped.\n",
      "[INFO] Scraping category: reis -> https://shop.rewe.de/c/reis/?objectsPerPage=80&search=reis\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 78 products on page 1.\n",
      "[INFO] Total products found: 78\n",
      "[INFO] reis: 78 products scraped.\n",
      "[INFO] Scraping category: sossen -> https://shop.rewe.de/c/sossen/?search=mayonnaise\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 34 products on page 1.\n",
      "[INFO] Total products found: 34\n",
      "[INFO] sossen: 34 products scraped.\n",
      "[INFO] Scraping category: sossen -> https://shop.rewe.de/c/sossen/?search=ketchup\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 38 products on page 1.\n",
      "[INFO] Total products found: 38\n",
      "[INFO] sossen: 38 products scraped.\n",
      "[INFO] Scraping category: nudeln -> https://shop.rewe.de/c/nudeln/?search=spaghetti\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 31 products on page 1.\n",
      "[INFO] Total products found: 31\n",
      "[INFO] nudeln: 31 products scraped.\n",
      "[INFO] Scraping category: eier-ei-ersatz -> https://shop.rewe.de/c/eier-ei-ersatz/?search=eier\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 22 products on page 1.\n",
      "[INFO] Total products found: 22\n",
      "[INFO] eier-ei-ersatz: 22 products scraped.\n",
      "[INFO] Scraping category: frischmilch -> https://shop.rewe.de/c/frischmilch/?objectsPerPage=80&search=milch\n",
      "[INFO] Scraping products on page 1...\n",
      "[INFO] Found 25 products on page 1.\n",
      "[INFO] Total products found: 25\n",
      "[INFO] frischmilch: 25 products scraped.\n",
      "[DONE] All products saved to rewe-products.json\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "\n",
    "def extract_category(url: str) -> str:\n",
    "    match = re.search(r\"/c/([^/?]+)\", url)\n",
    "    return match.group(1) if match else url\n",
    "\n",
    "def read_links_from_file(file_path: str):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def accept_cookies(driver):\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        buttons = wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, \"button\")))\n",
    "        for btn in buttons:\n",
    "            if \"alle erlauben\" in btn.text.lower():\n",
    "                btn.click()\n",
    "                print(\"[INFO] Cookies accepted.\")\n",
    "                time.sleep(2)\n",
    "                return\n",
    "    except Exception:\n",
    "        print(\"[INFO] No cookie modal or already accepted.\")\n",
    "\n",
    "def select_abholservice(driver):\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        buttons = wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, \"button\")))\n",
    "        for btn in buttons:\n",
    "            if \"abholservice\" in btn.text.lower():\n",
    "                btn.click()\n",
    "                print(\"[INFO] Abholservice selected.\")\n",
    "                time.sleep(2)\n",
    "                return\n",
    "    except Exception:\n",
    "        print(\"[INFO] No Abholservice modal or already handled.\")\n",
    "\n",
    "def enter_plz_and_select_market(driver):\n",
    "    try:\n",
    "        time.sleep(2)\n",
    "        plz_input = driver.find_element(By.TAG_NAME, \"input\")\n",
    "        plz_input.clear()\n",
    "        plz_input.send_keys(\"10119\")\n",
    "        plz_input.submit()\n",
    "        print(\"[INFO] PLZ entered and submitted.\")\n",
    "        time.sleep(3)\n",
    "    except Exception:\n",
    "        print(\"[WARN] Failed to enter PLZ.\")\n",
    "\n",
    "    try:\n",
    "        for _ in range(20):\n",
    "            buttons = driver.find_elements(By.TAG_NAME, \"button\")\n",
    "            for btn in buttons:\n",
    "                if \"abholmarkt wählen\" in btn.text.lower():\n",
    "                    btn.click()\n",
    "                    print(\"[INFO] Abholmarkt selected.\")\n",
    "                    time.sleep(3)\n",
    "                    return\n",
    "            time.sleep(1)\n",
    "        print(\"[WARN] No 'Abholmarkt wählen' button found.\")\n",
    "    except Exception:\n",
    "        print(\"[ERROR] Error selecting Abholmarkt.\")\n",
    "\n",
    "def enable_stealth(driver):\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "        \"source\": \"\"\"\n",
    "        Object.defineProperty(navigator, 'webdriver', {get: () => undefined});\n",
    "        Object.defineProperty(navigator, 'languages', {get: () => ['en-US', 'en']});\n",
    "        Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});\n",
    "        \"\"\"\n",
    "    })\n",
    "\n",
    "def scrape_products_from_category(driver, url):\n",
    "    driver.get(url)\n",
    "    accept_cookies(driver)\n",
    "    select_abholservice(driver)\n",
    "\n",
    "    products = []\n",
    "    page_num = 1\n",
    "\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 30)\n",
    "        wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"article.search-service-product\")))\n",
    "        time.sleep(2)\n",
    "        print(f\"[INFO] Scraping products on page {page_num}...\")\n",
    "\n",
    "        product_elements = driver.find_elements(By.CSS_SELECTOR, \"article.search-service-product\")\n",
    "\n",
    "        for el in product_elements:\n",
    "            try:\n",
    "                image_elem = el.find_element(By.TAG_NAME, \"img\")\n",
    "                name = image_elem.get_attribute(\"alt\").strip()\n",
    "                imageUrl = image_elem.get_attribute(\"src\")\n",
    "            except:\n",
    "                name = \"\"\n",
    "                imageUrl = \"\"\n",
    "\n",
    "            try:\n",
    "                price = el.find_element(By.CSS_SELECTOR, \"div.productPrice, .search-service-productPrice\").text.strip().replace(\"\\n\", \"\")\n",
    "            except:\n",
    "                price = \"\"\n",
    "\n",
    "            try:\n",
    "                unit = el.find_element(By.CSS_SELECTOR, \"div.productGrammage, .search-service-productGrammage\").text.strip()\n",
    "            except:\n",
    "                unit = \"\"\n",
    "\n",
    "            products.append({\"name\": name, \"price\": price, \"unit\": unit, \"imageUrl\": imageUrl})\n",
    "\n",
    "        print(f\"[INFO] Found {len(product_elements)} products on page {page_num}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error scraping products: {e}\")\n",
    "\n",
    "    print(f\"[INFO] Total products found: {len(products)}\")\n",
    "    return products\n",
    "\n",
    "def main():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    # Do NOT run headless because CAPTCHA needs manual solving\n",
    "    # options.add_argument(\"--headless\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.set_window_size(1920, 1080)\n",
    "    enable_stealth(driver)\n",
    "\n",
    "    links = read_links_from_file(\"links.txt\")\n",
    "    result = {}\n",
    "\n",
    "    if not links:\n",
    "        print(\"[ERROR] No links found in links.txt\")\n",
    "        return\n",
    "\n",
    "    first_url = links[0]\n",
    "    print(f\"[INFO] Setting PLZ and market on: {first_url}\")\n",
    "    driver.get(first_url)\n",
    "    accept_cookies(driver)\n",
    "    select_abholservice(driver)\n",
    "    enter_plz_and_select_market(driver)\n",
    "\n",
    "    print(\"[ACTION] If a CAPTCHA appears, please solve it manually in the browser.\")\n",
    "    input(\"Press Enter after solving the CAPTCHA to continue scraping...\")\n",
    "\n",
    "    for url in links:\n",
    "        category = extract_category(url)\n",
    "        print(f\"[INFO] Scraping category: {category} -> {url}\")\n",
    "        products = scrape_products_from_category(driver, url)\n",
    "        result[category] = products\n",
    "        print(f\"[INFO] {category}: {len(products)} products scraped.\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    with open(\"rewe-products-10119.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"[DONE] All products saved to rewe-products.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
