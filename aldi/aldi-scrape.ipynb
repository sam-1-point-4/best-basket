{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading https://www.aldi-nord.de/angebote/aktion-mo-02-06/frischkaesezubereitung-1011877-0-0.article.html\n",
      "[SAVED] aldi_html/page_001.html\n",
      "[INFO] Downloading https://www.aldi-nord.de/produkt/bio-feta-4575-0-0.article.html#/sortiment/kuehlung-tiefkuehlung/kaese-milch-milchprodukte/kaese\n",
      "[SAVED] aldi_html/page_002.html\n",
      "[INFO] Downloading https://www.aldi-nord.de/produkt/premium-cornichons-4096-0-0.article.html#/sortiment/nahrungsmittel/konserven\n",
      "[SAVED] aldi_html/page_003.html\n",
      "[INFO] Downloading https://www.aldi-nord.de/produkt/energy-drink-classic-1004898-0-0.article.html#/sortiment/getraenke/sport-energy-drinks\n",
      "[SAVED] aldi_html/page_004.html\n",
      "[INFO] Downloading https://www.aldi-nord.de/angebote/aktion-mo-02-06/bananen-6151-0-0.article.html\n",
      "[SAVED] aldi_html/page_005.html\n",
      "[INFO] Downloading https://www.aldi-nord.de/produkt/merci-3967-0-0.article.html#/sortiment/snacks-suessigkeiten/schokolade\n",
      "[SAVED] aldi_html/page_006.html\n",
      "[INFO] Downloading https://www.aldi-nord.de/angebote/aktion-di-10-06/mie-nudeln-1038295-0-0.article.html\n",
      "[SAVED] aldi_html/page_007.html\n",
      "[INFO] Downloading https://www.aldi-nord.de/produkt/pampers-premium-protection-1918-0-0.article.html#/sortiment/markenprodukte\n",
      "[SAVED] aldi_html/page_008.html\n",
      "[INFO] Downloading https://www.aldi-nord.de/angebote/aktion-mo-02-06/wassermelone-7200-0-0.article.html\n",
      "[SAVED] aldi_html/page_009.html\n",
      "[INFO] Downloading https://www.aldi-nord.de/produkt/paprika-rot-3911-0-0.article.html#/sortiment/obst-und-gemuese\n",
      "[SAVED] aldi_html/page_010.html\n",
      "[INFO] Downloading https://www.aldi-nord.de/produkt/frische-vollmilch-1019003-0-0.article.html#/sortiment/frische\n",
      "[SAVED] aldi_html/page_011.html\n",
      "[INFO] Downloading https://www.aldi-nord.de/angebote/aktion-sa-14-06/pesto-1013082-0-0.article.html\n",
      "[SAVED] aldi_html/page_012.html\n",
      "[INFO] Downloading https://www.aldi-nord.de/produkt/apfelschorle-0291-0-0.article.html#/sortiment/getraenke/limonaden-schorlen\n",
      "[SAVED] aldi_html/page_013.html\n",
      "[INFO] Downloading https://www.aldi-nord.de/produkt/eier-aus-bodenhaltung-1010204-0-0.article.html#/sortiment/nahrungsmittel/backzutaten/eier\n",
      "[SAVED] aldi_html/page_014.html\n",
      "[INFO] Downloading https://www.aldi-nord.de/angebote/aktion-mo-02-06/eisbergsalat-6276-0-0.article.html\n",
      "[SAVED] aldi_html/page_015.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"aldi_html\", exist_ok=True)\n",
    "\n",
    "# Read URLs from file\n",
    "with open(\"aldi-links.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    urls = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/114.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "for i, url in enumerate(urls, start=1):\n",
    "    try:\n",
    "        print(f\"[INFO] Downloading {url}\")\n",
    "        response = requests.get(url.split(\"#\")[0], headers=headers, timeout=15)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            filename = f\"aldi_html/page_{i:03}.html\"\n",
    "            with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(response.text)\n",
    "            print(f\"[SAVED] {filename}\")\n",
    "        else:\n",
    "            print(f\"[ERROR] Failed to fetch {url} (Status code: {response.status_code})\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Exception occurred for {url}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing page_016.html: [Errno 2] No such file or directory: 'aldi_html/page_016.html'\n",
      "Error processing page_017.html: [Errno 2] No such file or directory: 'aldi_html/page_017.html'\n",
      "Error processing page_018.html: [Errno 2] No such file or directory: 'aldi_html/page_018.html'\n",
      "Error processing page_019.html: [Errno 2] No such file or directory: 'aldi_html/page_019.html'\n",
      "Error processing page_020.html: [Errno 2] No such file or directory: 'aldi_html/page_020.html'\n",
      "Error processing page_021.html: [Errno 2] No such file or directory: 'aldi_html/page_021.html'\n",
      "✅ Extracted data saved to: aldi_html/aldi_products.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Directory containing the HTML files\n",
    "directory = \"aldi_html\"\n",
    "\n",
    "# Range of file numbers\n",
    "file_range = range(1, 22)  # 001 to 021\n",
    "\n",
    "# Output list\n",
    "products = []\n",
    "\n",
    "for i in file_range:\n",
    "    filename = f\"page_{i:03}.html\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "            soup = BeautifulSoup(file, \"html.parser\")  # Use 'lxml' if installed\n",
    "\n",
    "            # Extract product title\n",
    "            title_tag = soup.find(\"meta\", property=\"og:title\")\n",
    "            title = title_tag[\"content\"].strip() if title_tag else \"N/A\"\n",
    "\n",
    "            # Extract amount info\n",
    "            amount_tag = soup.find(\"span\", class_=\"price__unit\")\n",
    "            amount = amount_tag.text.strip() if amount_tag else \"N/A\"\n",
    "\n",
    "            # Extract image URL\n",
    "            image_tag = soup.find(\"meta\", property=\"og:image\")\n",
    "            image_url = image_tag[\"content\"].strip() if image_tag else \"N/A\"\n",
    "\n",
    "            # Extract price\n",
    "            price_wrapper = soup.find(\"span\", class_=\"price__wrapper\")\n",
    "            price = price_wrapper.text.strip().replace(\"\\n\", \"\") if price_wrapper else \"N/A\"\n",
    "\n",
    "            products.append({\n",
    "                \"file\": filename,\n",
    "                \"title\": title,\n",
    "                \"amount\": amount,\n",
    "                \"price\": price,\n",
    "                \"image\": image_url\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "# Save to JSON\n",
    "output_path = os.path.join(directory, \"aldi_products.json\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as out_file:\n",
    "    json.dump(products, out_file, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Extracted data saved to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
